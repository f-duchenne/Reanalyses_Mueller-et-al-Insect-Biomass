
#' 
#' **Weather explains variability in insect biomass, but not its temporal decline**
#'
#' François Duchenne
#' Based on the code provided by 
#' Jörg Müller, Torsten Hothorn, Ye Yuan, Sebastian Seibold, Oliver Mitesser, Julia Rothacher, 
#' Julia Freund, Clara Wild, Marina Wolz, Annette Menzel (revised and resubmitted, 2023)
#'
#' This document reproduces tables and figures.
#'

#'
#' Check for packages and if necessary install into library 
#+ message = FALSE
rm(list=ls())
pkgs <- c("mgcv", "knitr", "multcomp", "coin", "colorspace", "ggplot2", 
          "data.table", "tidyverse", "vegan","sf","gridExtra","scales",
		  "ggeffects","ggforce","raster","viridis","ggnewscale","ggdensity","lme4","cowplot","devtools","ggpubr","ggthemes") 

inst <- pkgs %in% installed.packages()
if (any(inst)) install.packages(pkgs[!inst])
pkg_out <- lapply(pkgs, require, character.only = TRUE)
#' Results were obtained in this environment
date()
sessionInfo()

if (!("gammit" %in% installed.packages())) install_github("m-clark/gammit")
library(gammit) 

#' Set working directory
setwd(dir="C:/Users/Duchenne/Documents/Mueller et al Insect Biomass data and R code")
#' The HTML output file was generated by
#library("knitr")
#spin("analysis.R")

#' Estimation method for mgcv::gam(),
#' see https://github.com/DistanceDevelopment/dsm/wiki/Why-is-the-default-smoothing-method-%22REML%22-rather-than-%22GCV.Cp%22%3F
#'
#' Results were compared with both options, results differed marginally
METHOD <- "REML"  ### or "GCV.Cp"
#'

#' Reading all data including published data by Hallmann et al. (2017) PLoS One 12: e0185809 until 2016 (data_org) 
#' and new data collected by our own in 2016, 2019, 2020, 2022 (validation)
data_org <-read.csv2("Data_Update_Revision_spells.csv", header = TRUE)

#' Setup factor coding for year (for plots only)
yr <- as.character(data_org$year)
t16 <- which(yr == "2016" & data_org$dataset == "training")
yr[t16] <- "2016t"
v16 <- which(yr == "2016" & data_org$dataset == "validation")
yr[v16] <- "2016v"
lev <- c(1989:2015, "2016t", "2016v", 2017:2022)
data_org$fyear <- factor(yr, levels = lev, labels = lev)


#FIGURE 1 of the answer:
shp=st_read("NUTS_RG_20M_2021_3035.shp") #available here: https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts#nuts21
shp=subset(shp,LEVL_CODE==0)
shp=st_transform(shp,crs=4326)

margin_map=1

r <- raster("hfp-europe-geo-grid/hfp-europe-geo-grid/hfp_Europe_grid/hfp_europe/hdr.adf") #available here: https://sedac.ciesin.columbia.edu/data/set/wildareas-v2-human-footprint-geographic/data-download
x <- c(xmin=min(data_org$E)-margin_map-1,xmax=max(data_org$E)+margin_map+1)
y <- c(ymin=min(data_org$N)-margin_map-1,ymax=56+1)
xy <- cbind(x,y)
S <- SpatialPoints(xy)
r <- crop(r, extent(bbox(S)), snap="out")
r2=as.data.frame(rasterToPoints(r))

#### EXTRACT HFI values
obj=st_as_sf(data_org,coords=c("E","N"))
st_crs(obj)=CRS("EPSG:4326")
obj=st_transform(obj,st_crs(r))
data_org$HFI=extract(r,obj)

#' Centering the variables precipitation and temperature during sampling on the mean value  
#' (Temp 16.263, Prec 26.87)
#'
#' This allows easier interpretation in the presence of interaction terms
data_org$Tmean_c <- data_org$Tmean -16.263
data_org$Psum_c <- data_org$Psum - 26.87
data_org$year_c <- data_org$year - mean(data_org$year)
data_org$site=as.factor(data_org$plot)

################################################################################################################ TABLE 1
#' **Splitting in training and validation data**
#'
#' Data published in Hallmann et al. (2017) PLoS One 12: e0185809
dim(training <- subset(data_org, dataset == "training"))
training$year <- as.double(training$year)
training$year_c=training$year-mean(training$year)
#' Own data published partly Uhler et al (2021) Nat Commun. 12(1):5946, 
#' Uhler et al. (2022) Insect Conservation and Diversity 10.1111/icad.12604, 
#' Busse et al. (2022) Insect Conservation and Diversity 10.1111/icad.12592
dim(validation <- subset(data_org, dataset == "validation"))

#' **Generalized additive models** a la Uhler et al (2021) Nat Commun. 12(1):5946.
#' 
#' Model 5 substituting year by anomalies
#'

#' **Model 5:** with weather anomalies instead of year
model5 <- gam(biomass ~ s(meandaynr) + offset(log(todaynr - fromdaynr)) + s(E, N, bs = "tp") +
                               nHerbs + nTrees + Light + ellenTemperature +
                               Arableland + Forest + Grassland + Water +s(year)+ 
                               Tmean_c * Psum_c + 
                               Tmean_anomaly_april_current * Psum_anomaly_april_current + 
                               Tmean_anomaly_april_prev * Psum_anomaly_april_prev + 
                               Tmean_anomaly_winter * Psum_anomaly_winter + 
                               Tmean_anomaly_meandaynr_prev * Psum_anomaly_meandaynr_prev,
                      family = gaussian(link = "log"), 
                      method = METHOD, 
                      data = training)

obj1=summary(model5)
res1=data.frame(Estimate=obj1$p.coeff,se=obj1$se[1:length(obj1$p.coeff)],pval=obj1$p.pv,aic=AIC(model5),resq=obj1$r.sq,varia=names(obj1$p.coeff))
AIC(model5)

#' **New Model:** with weather anomalies AND year
cor(training[,c("year_c","Tmean_c","Psum_c","Tmean_anomaly_april_current","Psum_anomaly_april_current","Tmean_anomaly_april_prev",
"Psum_anomaly_april_prev","Tmean_anomaly_winter","Psum_anomaly_winter","Tmean_anomaly_meandaynr_prev","Psum_anomaly_meandaynr_prev")])

checkmodel=lm(year_c ~ 	Tmean_c * Psum_c + 
						Tmean_anomaly_april_current * Psum_anomaly_april_current + 
						Tmean_anomaly_april_prev * Psum_anomaly_april_prev + 
						Tmean_anomaly_winter * Psum_anomaly_winter + 
						Tmean_anomaly_meandaynr_prev * Psum_anomaly_meandaynr_prev,data=training)
summary(checkmodel)

modelbis <- gam(biomass ~ s(meandaynr) + offset(log(todaynr - fromdaynr)) + s(E, N, bs = "tp") +
                               nHerbs + nTrees + Light + ellenTemperature +
                               Arableland + Forest + Grassland + Water +
							   year_c+ 
                               Tmean_c * Psum_c + 
                               Tmean_anomaly_april_current * Psum_anomaly_april_current + 
                               Tmean_anomaly_april_prev * Psum_anomaly_april_prev + 
                               Tmean_anomaly_winter * Psum_anomaly_winter + 
                               Tmean_anomaly_meandaynr_prev * Psum_anomaly_meandaynr_prev,
                      family = gaussian(link = "log"), 
                      method = METHOD, 
                      data = training)
obj=summary(modelbis)
res2=data.frame(Estimate=obj$p.coeff,se=obj$se[1:length(obj$p.coeff)],pval=obj$p.pv,aic=AIC(modelbis),resq=obj$r.sq,varia=names(obj$p.coeff))
AIC(modelbis)

#TABLE 1
resf=merge(res1,res2,by="varia",all=T)
resf$varia=factor(resf$varia,levels=c("(Intercept)","nHerbs","nTrees","Light","ellenTemperature","Arableland","Forest","Grassland","Water",
"Tmean_c","Psum_c","Tmean_c:Psum_c",
"Tmean_anomaly_winter","Psum_anomaly_winter","Tmean_anomaly_winter:Psum_anomaly_winter",
"Tmean_anomaly_april_current","Psum_anomaly_april_current","Tmean_anomaly_april_current:Psum_anomaly_april_current",                   
"Tmean_anomaly_april_prev","Psum_anomaly_april_prev","Tmean_anomaly_april_prev:Psum_anomaly_april_prev",
"Tmean_anomaly_meandaynr_prev","Psum_anomaly_meandaynr_prev","Tmean_anomaly_meandaynr_prev:Psum_anomaly_meandaynr_prev"))
resf=resf[order(resf$varia),]
fwrite(resf,"table_1.csv")

################################################################################################################ FIGURE 1
#PREDICTING the trend using the modified model
newdata=data.frame(meandaynr=mean(training$meandaynr),nHerbs=mean(training$nHerbs),nTrees =mean(training$nTrees ),
Light=mean(training$Light),ellenTemperature=mean(training$ellenTemperature),Arableland=mean(training$Arableland),
Forest=mean(training$Forest),
Grassland =mean(training$Grassland ),Water=mean(training$Water),Tmean_c=mean(training$Tmean_c),Psum_c=mean(training$Psum_c),
Tmean_anomaly_april_current=mean(training$Tmean_anomaly_april_current),
Psum_anomaly_april_current=mean(training$Psum_anomaly_april_current),
Tmean_anomaly_april_prev=mean(training$Tmean_anomaly_april_prev),Psum_anomaly_april_prev =mean(training$Psum_anomaly_april_prev),
Tmean_anomaly_winter=mean(training$Tmean_anomaly_winter),Psum_anomaly_winter =mean(training$Psum_anomaly_winter),
Tmean_anomaly_meandaynr_prev=mean(training$Tmean_anomaly_meandaynr_prev),Psum_anomaly_meandaynr_prev =mean(training$Psum_anomaly_meandaynr_prev),
year_c=1989:2016-mean(training$year),todaynr=10,fromdaynr=0,E=mean(training$E),N=mean(training$N))

pre1=as.data.frame(predict(modelbis,type="response",newdata=newdata,se.fit=TRUE))
pre1$dataset2="training"

#compute partial residuals
newdat=training
newdat$year_c=mean(training$year_c)
training$partial_resid=training$biomass-predict(modelbis,newdata=newdat,type="response")
training$dataset2="training"
#correct the predicts to get partial predicts
pre1$fit=pre1$fit-mean(predict(modelbis,newdata=newdat,type="response"))

pref=pre1
pref$year=c(1989:2016)

#PLOT PREDICTIONS
pl1=ggplot()+geom_hline(yintercept=0,linetype="dashed")+
geom_point(data=training,aes(x=year,y=partial_resid/10),color="#0B4F6C",alpha=0.3)+
geom_ribbon(data=pref,aes(x=year,ymin=fit/10-1.96*se.fit/10,ymax=fit/10+1.96*se.fit/10),alpha=0.2,fill="#0B4F6C")+
geom_line(data=pref,aes(x=year,y=fit/10),size=1.2,color="#0B4F6C")+
theme_bw()+theme(panel.grid=element_blank(),plot.title=element_text(size=14,face="bold",hjust = 0),
legend.position="right",panel.border = element_blank(),axis.line= element_line(),axis.text.x=element_text(angle=0))+
ggtitle("a")+
xlab("Years")+ylab("Partial residuals of biomass (g per day)")#+facet_zoom(y=TRUE,ylim =c(10,-10),split = TRUE)

#' Assessing stability of results: Add year as random effect #Model from Muller et al.
hallmann_plus_RE <- gam(biomass ~ s(meandaynr) + offset(log(todaynr - fromdaynr)) + s(E, N, bs = "tp") +
                               s(fyear, bs = "re") +  ### add temporal random effect
                               nHerbs + nTrees + Light + ellenTemperature +
                               Arableland + Forest + Grassland + Water + 
                               Tmean_c * Psum_c + 
                               Tmean_anomaly_april_current * Psum_anomaly_april_current + 
                               Tmean_anomaly_april_prev * Psum_anomaly_april_prev + 
                               Tmean_anomaly_winter * Psum_anomaly_winter + 
                               Tmean_anomaly_meandaynr_prev * Psum_anomaly_meandaynr_prev,
                      family = gaussian(link = "log"), 
                      method = METHOD, 
                      data = training)
summary(hallmann_plus_RE)

obj=extract_ranef(hallmann_plus_RE, re ="fyear", ci_level = 0.95, digits = 3)
obj$year=as.numeric(obj$group)
obj$year[is.na(obj$year)]=2016

pl2=ggplot(data=obj,aes(x=year,y=value,ymin=lower_2.5,ymax=upper_97.5))+geom_hline(yintercept=0,linetype="dashed")+geom_pointrange(color="#0B4F6C")+
theme_bw()+theme(panel.grid=element_blank(),plot.title=element_text(size=14,face="bold",hjust = 0),
legend.position="right",panel.border = element_blank(),axis.line= element_line(),axis.text.x=element_text(angle=0))+
ggtitle("b")+
xlab("Years")+ylab("Random year effect")+stat_smooth(method="lm",color="#0B4F6C",alpha=0.2)+stat_cor(aes(label = paste(..rr.label.., ..p.label.., sep = "*`,`~")),label.x=2006)


############################## VALIDATION
#' Predict single effects from model5 model for later validation data
X <- predict(modelbis, newdata = validation, type = "terms",se.fit=T)
#' Aggregate contributions by weather variables
wvar <- grep("^[TP]", colnames(X$fit))
#' Combine all terms with weather and weather anomalies into a new variable
#' This defines the waether score
validation2=validation
validation2$weather <-  rowSums(X$fit[, c(wvar)])
validation2$model2="modified model"
#Observed biomass per day
validation2$logbm <- log(validation2$biomass_adj/(validation2$todaynr - validation2$fromdaynr))
validation2$bm <- validation2$biomass_adj/(validation2$todaynr - validation2$fromdaynr)
validation2$plot <- factor(validation2$plot)

#model modified
spearman_test(weather ~ logbm | plot, data = validation2)

pl3=ggplot(data=validation2,aes(x=weather,y=bm,color=as.factor(year)))+geom_point()+
stat_cor(method ="spearman",aes(label = ..r.label..),output.type ="expression",show_guide  = FALSE,cor.coef.name="rho",label.y.npc = "bottom",label.x.npc = "centre")+
scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
theme_bw()+theme(panel.grid=element_blank(),plot.title=element_text(size=14,face="bold",hjust = 0),
panel.border = element_blank(),axis.line= element_line(),axis.text.x=element_text(angle=0),strip.background=element_blank(),legend.position="none")+
xlab("Linear combination of weather conditions")+ylab("Biomass (g per day)")+labs(color="Year")+scale_color_colorblind()+ggtitle("c")

plot_grid(pl1,pl2,pl3,ncol=3,align="hv")

pdf("Fig1.pdf",width=10,height=4)
plot_grid(pl1,pl2,pl3,ncol=3,align="hv")
dev.off();

################################################################################################################ FIGURE 2

newdata=data.frame(meandaynr=mean(training$meandaynr),nHerbs=mean(training$nHerbs),nTrees =mean(training$nTrees ),
Light=mean(training$Light),ellenTemperature=mean(training$ellenTemperature),Arableland=mean(training$Arableland),
Forest=mean(training$Forest),
Grassland =mean(training$Grassland),Water=mean(training$Water),Tmean_c=mean(training$Tmean_c),Psum_c=mean(training$Psum_c),
Tmean_anomaly_april_current=training$Tmean_anomaly_april_current,
Psum_anomaly_april_current=training$Psum_anomaly_april_current,
Tmean_anomaly_april_prev=training$Tmean_anomaly_april_prev,Psum_anomaly_april_prev =training$Psum_anomaly_april_prev,
Tmean_anomaly_winter=training$Tmean_anomaly_winter,Psum_anomaly_winter =training$Psum_anomaly_winter,
Tmean_anomaly_meandaynr_prev=training$Tmean_anomaly_meandaynr_prev,Psum_anomaly_meandaynr_prev=training$Psum_anomaly_meandaynr_prev,
year_c=mean(training$year_c),todaynr=10,fromdaynr=0,E=mean(training$E),N=mean(training$N))

newdata1=cbind(newdata,as.data.frame(predict(modelbis,type="response",newdata=newdata,se.fit=TRUE)))
newdata1$year=training$year

model1=gam(fit ~ year,family = gaussian(link = "log"), method = METHOD, data = newdata1)
b1=as.data.frame(ggpredict(model1,tem="year")$year)

pl4=ggplot()+geom_point(data=newdata1,aes(x=year,y=fit/10),color="hotpink2",alpha=0.1)+
geom_ribbon(data=b1,aes(x=x,ymin=conf.low/10,ymax=conf.high/10),alpha=0.2,fill="hotpink4")+
geom_line(data=b1,aes(x=x,y=predicted/10),size=1.2,col="hotpink4")+theme_bw()+theme(panel.grid=element_blank(),plot.title=element_text(size=14,face="bold",hjust = 0),
legend.position="right",panel.border = element_blank(),axis.line= element_line(),axis.text.x=element_text(angle=0))+
ggtitle("a")+
xlab("Years")+ylab("Biomass predicted by weather conditions only\n(g per day)")

newdata=data.frame(meandaynr=mean(training$meandaynr),nHerbs=training$nHerbs,nTrees =training$nTrees,
Light=mean(training$Light),ellenTemperature=mean(training$ellenTemperature),Arableland=training$Arableland,
Forest=training$Forest,
Grassland =training$Grassland,Water=training$Water,Tmean_c=mean(training$Tmean_c),Psum_c=mean(training$Psum_c),
Tmean_anomaly_april_current=mean(training$Tmean_anomaly_april_current),
Psum_anomaly_april_current=mean(training$Psum_anomaly_april_current),
Tmean_anomaly_april_prev=mean(training$Tmean_anomaly_april_prev),Psum_anomaly_april_prev =mean(training$Psum_anomaly_april_prev),
Tmean_anomaly_winter=mean(training$Tmean_anomaly_winter),Psum_anomaly_winter =mean(training$Psum_anomaly_winter),
Tmean_anomaly_meandaynr_prev=mean(training$Tmean_anomaly_meandaynr_prev),Psum_anomaly_meandaynr_prev =mean(training$Psum_anomaly_meandaynr_prev),
year_c=mean(training$year_c),todaynr=10,fromdaynr=0,E=mean(training$E),N=mean(training$N))

newdata2=cbind(newdata,as.data.frame(predict(model5,type="response",newdata=newdata,se.fit=TRUE)))
newdata2$year=training$year
model2=gam(fit ~ year,family = gaussian(link = "log"), method = METHOD, data = newdata2)
b2=as.data.frame(ggpredict(model2,tem="year")$year)

summary(model2)

pl5=ggplot()+geom_point(data=newdata2,aes(x=year,y=fit/10),color="chartreuse3",alpha=0.1)+
geom_ribbon(data=b2,aes(x=x,ymin=conf.low/10,ymax=conf.high/10),alpha=0.2,fill="chartreuse4")+
geom_line(data=b2,aes(x=x,y=predicted/10),size=1.2,col="chartreuse4")+theme_bw()+theme(panel.grid=element_blank(),plot.title=element_text(size=14,face="bold",hjust = 0),
legend.position="right",panel.border = element_blank(),axis.line= element_line(),axis.text.x=element_text(angle=0))+
ggtitle("b")+
xlab("Years")+ylab("Biomass predicted by habitats conditions only\n(g per day)")


contrib=data.frame(variable=c("Unknown","Weather","Habitat","Total","Hallmann\net al."),esti=NA,conf.low=NA,conf.high=NA)
contrib[contrib$variable=="Weather",2:4]=exp(summary(model1)$p.coeff[2]+c(0,-1.96*summary(model1)$se[2],1.96*summary(model1)$se[2]))-1
contrib[contrib$variable=="Habitat",2:4]=exp(summary(model2)$p.coeff[2]+c(0,-1.96*summary(model2)$se[2],1.96*summary(model2)$se[2]))-1
contrib[contrib$variable=="Unknown",2:4]=exp(summary(modelbis)$p.coeff["year_c"]+c(0,-1.96*summary(modelbis)$se["year_c"],1.96*summary(modelbis)$se["year_c"]))-1
av=summary(modelbis)$p.coeff["year_c"]+summary(model2)$p.coeff[2]+summary(model1)$p.coeff[2]
sde=sqrt(summary(model1)$se[2]^2+summary(model2)$se[2]^2+summary(modelbis)$se["year_c"]^2)
contrib[contrib$variable=="Total",2:4]=exp(av+c(0,-1.96*sde,1.96*sde))-1
contrib[contrib$variable=="Hallmann\net al.",2:4]=exp(-0.063+c(0,-1.96*0.002,1.96*0.002))-1

colo=c("#0B4F6C","hotpink4","chartreuse4","grey25","grey")

contrib$variable=factor(contrib$variable,levels=c("Unknown","Weather","Habitat","Total","Hallmann\net al."))
pl6=ggplot(data=contrib,aes(x=variable,y=esti,fill=variable))+geom_bar(stat="identity")+geom_errorbar(aes(ymin=conf.low, ymax=conf.high),width=0.2)+
geom_hline(yintercept=0)+
theme_bw()+theme(panel.grid=element_blank(),plot.title=element_text(size=14,face="bold",hjust = 0),
legend.position="none",panel.border = element_blank(),axis.line= element_line(),axis.text.x=element_text(angle=20,hjust=1),axis.title.x=element_blank())+
ggtitle("c")+scale_fill_manual(values=colo)+scale_y_continuous(labels=percent)+ylab("growth rate (%/year)")

plot_grid(pl4,pl5,pl6,align="hv",ncol=3)

pdf("Fig2.pdf",width=10,height=4)
plot_grid(pl4,pl5,pl6,align="hv",ncol=3)
dev.off();

################################################################################################################ FIGURE 3
pl7=ggplot(data=data_org,aes(x=fyear,y=biomass_adj/(todaynr-fromdaynr),fill=dataset))+geom_boxplot()+
theme_bw()+theme(panel.grid=element_blank(),plot.title=element_text(size=14,face="bold",hjust = 0),
legend.position="none",panel.border = element_blank(),axis.line= element_line(),axis.text.x=element_text(angle=90,vjust=0.5))+
ggtitle("a")+
xlab("Years")+ylab("Biomass (g per day)")+
scale_x_discrete(breaks=c(1989:2015, "2016t", "2016v", 2017:2022),drop=F)+
scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),labels = trans_format("log10", math_format(10^.x)))+
scale_color_manual(values=c("#0B4F6C","#CBB9A8"))+scale_fill_manual(values=c("#0B4F6C","#CBB9A8"))

pl8=ggplot()+geom_sf(data=shp)+xlim(c(min(data_org$E)-margin_map,max(data_org$E)+margin_map))+ylim(c(min(data_org$N)-margin_map,56))+
geom_point(data=data_org,aes(x=E,y=N,fill=dataset),color="black",shape=21,alpha=0.4)+
theme_bw()+theme(panel.grid=element_blank(),plot.title=element_text(size=14,face="bold",hjust = 0),
legend.position="none",panel.border = element_blank(),axis.line= element_line(),axis.text.x=element_text(angle=90),
axis.title=element_blank())+
ggtitle("b")+
scale_color_manual(values=c("#0B4F6C","#CBB9A8"))+scale_fill_manual(values=c("#0B4F6C","#CBB9A8"))+coord_sf(expand=F)

pl9=ggplot()+geom_raster(data=r2,aes(x=x,y=y,fill=hfp_europe))+
geom_sf(data=shp,fill=NA,col="black",linewidth=0.7)+
xlim(c(min(data_org$E)-margin_map,max(data_org$E)+margin_map))+ylim(c(min(data_org$N)-margin_map,56))+
scale_fill_gradientn(colors=alpha(c("white","lightyellow","firebrick4","red"),1),name="HFI")+
new_scale_fill()+
#geom_point(data=data_org,aes(x=E,y=N,),color="black",shape=21,fill=NA)+
#geom_hdr(data=data_org,aes(x=E,y=N,color=dataset),probs=c(0.95),fill=NA,linewidth=2)+
scale_fill_manual(values=alpha(c("#0B4F6C","#CBB9A8"),0.1),guide=FALSE)+
scale_colour_manual(values=alpha(c("#0B4F6C","#CBB9A8"),1),guide=FALSE)+
theme_bw()+
theme(panel.grid=element_blank(),plot.title=element_text(size=14,face="bold",hjust = 0),
legend.position="bottom",panel.border = element_blank(),axis.line= element_line(),axis.text.x=element_text(angle=90),
axis.title=element_blank())+
ggtitle("c")+coord_sf(expand=F)

pl10=ggplot(data=data_org,aes(x=dataset,y=HFI,color=dataset))+geom_boxplot()+
theme_bw()+theme(panel.grid=element_blank(),plot.title=element_text(size=14,face="bold",hjust = 0),
legend.position="none",panel.border = element_blank(),axis.line= element_line(),axis.text.x=element_text(angle=0))+
ggtitle("d")+
xlab("")+ylab("Human Footprint Index (HFI)")+
scale_color_manual(values=c("#0B4F6C","#CBB9A8"))+scale_fill_manual(values=c("#0B4F6C","#CBB9A8"))

grid.arrange(pl7,pl8,pl9,pl10,layout_matrix=rbind(c(1,2,4),c(1,3,4)),widths=c(2.5,1,1),heights=c(1,1.3))

pdf("Fig3.pdf",width=9,height=5)
grid.arrange(pl7,pl8,pl9,pl10,layout_matrix=rbind(c(1,2,4),c(1,3,4)),widths=c(2.5,1,0.8),heights=c(1,1.3))
dev.off();


training$duration=log(training$todaynr - training$fromdaynr)
modelf=randomForest(biomass ~ meandaynr +duration +E+N+
                               year_c+
                               nHerbs + nTrees + Light + ellenTemperature +
                               Arableland + Forest + Grassland + Water + 
                               Tmean_c + Psum_c + 
                               Tmean_anomaly_april_current + Psum_anomaly_april_current + 
                               Tmean_anomaly_april_prev + Psum_anomaly_april_prev + 
                               Tmean_anomaly_winter + Psum_anomaly_winter + 
                               Tmean_anomaly_meandaynr_prev + Psum_anomaly_meandaynr_prev,
                      importance=T,data = training)